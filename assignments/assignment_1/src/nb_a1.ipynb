{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment concerns using ```spaCy``` to extract linguistic information from a corpus of texts.\n",
    "\n",
    "The corpus is an interesting one: *The Uppsala Student English Corpus (USE)*. All of the data is included in the folder called ```in``` but you can access more documentation via [this link](https://ota.bodleian.ox.ac.uk/repository/xmlui/handle/20.500.12024/2457).This assignment concerns using ```spaCy``` to extract linguistic information from a corpus of texts.\n",
    "\n",
    "The corpus is an interesting one: *The Uppsala Student English Corpus (USE)*. All of the data is included in the folder called ```in``` but you can access more documentation via [this link](https://ota.bodleian.ox.ac.uk/repository/xmlui/handle/20.500.12024/2457)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in packages\n",
    "import os\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# loading spacy\n",
    "# download spacy module: python -m spacy download en_core_web_md\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Loop over each text file in the folder called ```in```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining path to folder\n",
    "folder = os.path.join(\"..\", \"in\", \"USEcorpus\")\n",
    "\n",
    "# Empty list for our texts\n",
    "texts = []\n",
    "\n",
    "# Walk through the folder and its subdirectories\n",
    "for root, dirs, files in os.walk(folder):\n",
    "    for filename in files:\n",
    "        # Construct the full path to the file\n",
    "        file_path = os.path.join(root, filename)\n",
    "        # Add the file path to the list of texts\n",
    "        texts.append(file_path)\n",
    "\n",
    "# Processing each text file\n",
    "for text_path in texts:\n",
    "    with open(text_path, 'r',encoding='latin-1') as file:\n",
    "        content = file.read()\n",
    "\n",
    "        # create spaCy docs for each text\n",
    "        doc = nlp(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Extract the following information\n",
    "    - Relative frequency of Nouns, Verbs, Adjective, and Adverbs per 10,000 words\n",
    "    - Total number of *unique* PER, LOC, ORGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function for counting and calculating the frequency\n",
    "def count_freq(doc, pos_tag):\n",
    "    count = sum(1 for token in doc if token.pos_ == pos_tag)\n",
    "    relative_freq = (count / len(doc)) * 10000\n",
    "    print(f'The relative frequency per 10,000 words for {pos_tag.lower()}s is {round(relative_freq, 2)}')\n",
    "\n",
    "count_freq(doc, \"NOUN\")\n",
    "count_freq(doc, \"VERB\")\n",
    "count_freq(doc, \"ADJ\")\n",
    "count_freq(doc, \"ADV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_entities(doc):\n",
    "    entities = [ent.label_ for ent in doc.ents]\n",
    "    label_counts = {\"PER\": 0, \"LOC\": 0, \"ORG\": 0}\n",
    "    for entity_label in entities:\n",
    "        if entity_label in [\"PER\", \"PERSON\"]:\n",
    "            label_counts[\"PER\"] += 1\n",
    "        elif entity_label in [\"LOC\", \"GPE\"]:\n",
    "            label_counts[\"LOC\"] += 1\n",
    "        elif entity_label == \"ORG\":\n",
    "            label_counts[\"ORG\"] += 1\n",
    "    return label_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) For each sub-folder (a1, a2, a3, ...) save a table which shows the following information:\n",
    "\n",
    "|Filename|RelFreq NOUN|RelFreq VERB|RelFreq ADJ|RelFreq ADV|Unique PER|Unique LOC|Unique ORG|\n",
    "|---|---|---|---|---|---|---|---|\n",
    "|file1.txt|---|---|---|---|---|---|---|\n",
    "|file2.txt|---|---|---|---|---|---|---|\n",
    "|etc|---|---|---|---|---|---|---|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate table for a list of files in a folder\n",
    "def generate_table(folder_path):\n",
    "   \n",
    "    columns = ['Filename', 'RelFreq NOUN', 'RelFreq VERB', 'RelFreq ADJ', 'RelFreq ADV', 'Unique PER', 'Unique LOC', 'Unique ORG']\n",
    "    data = []\n",
    "    for file in files:\n",
    "        with open(os.path.join(folder_path, file), 'r') as f:\n",
    "            text = f.read()\n",
    "            doc = nlp(text)\n",
    "            row = [file]\n",
    "            row.extend([calculate_freq(doc, 'NOUN'), calculate_freq(doc, 'VERB'), calculate_freq(doc, 'ADJ'), calculate_freq(doc, 'ADV')])\n",
    "            entities_count = count_entities(doc)\n",
    "            row.extend([entities_count['PER'], entities_count['LOC'], entities_count['ORG']])\n",
    "            data.append(row)\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    return df\n",
    "\n",
    "# Generate tables for each sub-folder\n",
    "for i in range(1, 4):  # assuming you have subfolders named a1, a2, a3, etc.\n",
    "    folder_path = f'a{i}'\n",
    "    print(f\"Generating table for folder {folder_path}:\")\n",
    "    table = generate_table(folder_path)\n",
    "    print(table)\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
